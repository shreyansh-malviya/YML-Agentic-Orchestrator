2026-01-18 08:08:34 | INFO     | ================================================================================
2026-01-18 08:08:34 | INFO     | Logging initialized - Log file: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\logs\workflow_20260118_080834.log
2026-01-18 08:08:34 | INFO     | ================================================================================
2026-01-18 08:08:34 | INFO     | ================================================================================
2026-01-18 08:08:34 | INFO     | WORKFLOW EXECUTION STARTED
2026-01-18 08:08:34 | INFO     | Start Time: 2026-01-18 08:08:34
2026-01-18 08:08:34 | INFO     | YAML File: engine\examples\config_grok_example.yml
2026-01-18 08:08:34 | INFO     | ================================================================================
2026-01-18 08:08:34 | INFO     | Clearing context for fresh workflow start
2026-01-18 08:08:34 | DEBUG    | JSON context file reset: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\context\raw.json
2026-01-18 08:08:34 | DEBUG    | RAG memory cleared
2026-01-18 08:08:34 | INFO     | Context cleared successfully in 0.002s
2026-01-18 08:08:34 | INFO     | Loading YAML configuration from: engine\examples\config_grok_example.yml
2026-01-18 08:08:34 | INFO     | YAML loaded successfully in 0.00s
2026-01-18 08:08:34 | DEBUG    | Configuration contains 3 agents
2026-01-18 08:08:34 | DEBUG    | Workflow type: sequential
2026-01-18 08:08:34 | INFO     | Configuration Summary:
2026-01-18 08:08:34 | INFO     |   - Total Agents: 3
2026-01-18 08:08:34 | INFO     |   - Workflow Type: sequential
2026-01-18 08:08:34 | INFO     | ================================================================================
2026-01-18 08:08:34 | INFO     | EXECUTING SEQUENTIAL WORKFLOW
2026-01-18 08:08:34 | INFO     | ================================================================================
2026-01-18 08:08:34 | INFO     | Total steps in workflow: 3
2026-01-18 08:08:34 | DEBUG    | Step sequence: grok_researcher -> grok_analyst -> multi_llm_coordinator
2026-01-18 08:08:34 | INFO     | 
================================================================================
2026-01-18 08:08:34 | INFO     | STEP 1/3: Processing agent 'grok_researcher'
2026-01-18 08:08:34 | INFO     | ================================================================================
2026-01-18 08:08:34 | INFO     | Agent Role: Research Assistant using Grok
2026-01-18 08:08:34 | INFO     | Agent Goal: Research topics using xAI's Grok model
2026-01-18 08:08:34 | INFO     | Model: grok-beta
2026-01-18 08:08:34 | DEBUG    | Prompt length: 321 chars
2026-01-18 08:08:34 | DEBUG    | Saving context for role: User (length: 321 chars)
2026-01-18 08:08:34 | DEBUG    | Saved to JSON backup: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\context\raw.json
2026-01-18 08:08:39 | DEBUG    | Saved to RAG memory
2026-01-18 08:08:39 | DEBUG    | Context saved in 4.651s
2026-01-18 08:08:39 | INFO     | Sending request to grok-beta...
2026-01-18 08:08:39 | INFO     | Response received in 0.00s (62 chars)
2026-01-18 08:08:39 | INFO     | 
Research Assistant using Grok Response:
2026-01-18 08:08:39 | INFO     | ------------------------------------------------------------
2026-01-18 08:08:39 | INFO     | [Error: openai package not installed. Run: pip install openai]
2026-01-18 08:08:39 | INFO     | ------------------------------------------------------------
2026-01-18 08:08:39 | DEBUG    | Saving context for role: Research Assistant using Grok (length: 62 chars)
2026-01-18 08:08:39 | DEBUG    | Saved to JSON backup: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\context\raw.json
2026-01-18 08:08:39 | DEBUG    | Saved to RAG memory
2026-01-18 08:08:39 | DEBUG    | Context saved in 0.014s
2026-01-18 08:08:39 | INFO     | 
================================================================================
2026-01-18 08:08:39 | INFO     | STEP 2/3: Processing agent 'grok_analyst'
2026-01-18 08:08:39 | INFO     | ================================================================================
2026-01-18 08:08:39 | INFO     | Retrieving relevant context from previous steps (RAG)
2026-01-18 08:08:39 | DEBUG    | Retrieving relevant context (max: 5 memories)
2026-01-18 08:08:39 | DEBUG    | Retrieved 422 chars of relevant context in 0.016s
2026-01-18 08:08:39 | INFO     | Agent Role: Data Analyst using Grok
2026-01-18 08:08:39 | INFO     | Agent Goal: Analyze data and provide insights
2026-01-18 08:08:39 | INFO     | Model: grok-2-latest
2026-01-18 08:08:39 | DEBUG    | Including context in prompt
2026-01-18 08:08:39 | DEBUG    | Prompt length: 683 chars
2026-01-18 08:08:39 | DEBUG    | Saving context for role: User (length: 232 chars)
2026-01-18 08:08:39 | DEBUG    | Saved to JSON backup: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\context\raw.json
2026-01-18 08:08:39 | DEBUG    | Saved to RAG memory
2026-01-18 08:08:39 | DEBUG    | Context saved in 0.023s
2026-01-18 08:08:39 | INFO     | Sending request to grok-2-latest...
2026-01-18 08:08:39 | INFO     | Response received in 0.00s (62 chars)
2026-01-18 08:08:39 | INFO     | 
Data Analyst using Grok Response:
2026-01-18 08:08:39 | INFO     | ------------------------------------------------------------
2026-01-18 08:08:39 | INFO     | [Error: openai package not installed. Run: pip install openai]
2026-01-18 08:08:39 | INFO     | ------------------------------------------------------------
2026-01-18 08:08:39 | DEBUG    | Saving context for role: Data Analyst using Grok (length: 62 chars)
2026-01-18 08:08:39 | DEBUG    | Saved to JSON backup: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\context\raw.json
2026-01-18 08:08:39 | DEBUG    | Saved to RAG memory
2026-01-18 08:08:39 | DEBUG    | Context saved in 0.017s
2026-01-18 08:08:39 | INFO     | 
================================================================================
2026-01-18 08:08:39 | INFO     | STEP 3/3: Processing agent 'multi_llm_coordinator'
2026-01-18 08:08:39 | INFO     | ================================================================================
2026-01-18 08:08:39 | INFO     | Retrieving relevant context from previous steps (RAG)
2026-01-18 08:08:39 | DEBUG    | Retrieving relevant context (max: 5 memories)
2026-01-18 08:08:39 | DEBUG    | Retrieved 751 chars of relevant context in 0.016s
2026-01-18 08:08:39 | INFO     | Agent Role: Multi-LLM Coordinator
2026-01-18 08:08:39 | INFO     | Agent Goal: Coordinate responses from different LLMs
2026-01-18 08:08:39 | INFO     | Model: gemini-2.5-flash
2026-01-18 08:08:39 | DEBUG    | Including context in prompt
2026-01-18 08:08:39 | DEBUG    | Prompt length: 1008 chars
2026-01-18 08:08:39 | DEBUG    | Saving context for role: User (length: 228 chars)
2026-01-18 08:08:39 | DEBUG    | Saved to JSON backup: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\context\raw.json
2026-01-18 08:08:39 | DEBUG    | Saved to RAG memory
2026-01-18 08:08:39 | DEBUG    | Context saved in 0.020s
2026-01-18 08:08:39 | INFO     | Sending request to gemini-2.5-flash...
2026-01-18 08:08:40 | INFO     | Response received in 1.74s (914 chars)
2026-01-18 08:08:40 | INFO     | 
Multi-LLM Coordinator Response:
2026-01-18 08:08:40 | INFO     | ------------------------------------------------------------
2026-01-18 08:08:40 | INFO     | [Error calling Gemini: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash
Please retry in 19.946570046s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 20
}
, retry_delay {
  seconds: 19
}
]]
2026-01-18 08:08:40 | INFO     | ------------------------------------------------------------
2026-01-18 08:08:40 | DEBUG    | Saving context for role: Multi-LLM Coordinator (length: 914 chars)
2026-01-18 08:08:40 | DEBUG    | Saved to JSON backup: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\context\raw.json
2026-01-18 08:08:41 | DEBUG    | Saved to RAG memory
2026-01-18 08:08:41 | DEBUG    | Context saved in 0.049s
2026-01-18 08:08:41 | INFO     | ================================================================================
2026-01-18 08:08:41 | INFO     | WORKFLOW EXECUTION COMPLETED SUCCESSFULLY
2026-01-18 08:08:41 | INFO     | End Time: 2026-01-18 08:08:41
2026-01-18 08:08:41 | INFO     | Total Duration: 6.57 seconds
2026-01-18 08:08:41 | INFO     | Context saved to: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\context\raw.json
2026-01-18 08:08:41 | INFO     | Total memories in RAG: 6
2026-01-18 08:08:41 | INFO     | Log file: D:\Hackathons\Auraverse2_P2\YML-Agentic-Orchestrator\engine\logs\workflow_20260118_080834.log
2026-01-18 08:08:41 | INFO     | ================================================================================
